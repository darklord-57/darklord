{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b478e82a",
   "metadata": {},
   "source": [
    "# AMBER HEARD :\n",
    "    Explore trends in social media activity related to Amber Heard over time: You can use the daily counts of tweets, retweets, and replies to examine how social media activity related to Amber Heard changed over the course of 2018. Are there specific days or events that led to spikes in social media activity? What were the most common topics or hashtags associated with Amber Heard?\n",
    "\n",
    "    Conduct sentiment analysis to understand the emotional tone of social media activity related to Amber Heard: The dataset includes sentiment analysis scores for each day, which can help you to understand the overall emotional tone of social media activity related to Amber Heard. Are there specific events or controversies that led to more positive or negative sentiment scores?\n",
    "\n",
    "    Examine the network of Twitter users who engage with Amber Heard on social media: The dataset includes information about Twitter users who retweeted, replied to, or mentioned Amber Heard in their tweets. You can use this information to map out the network of Twitter users who engage with Amber Heard on social media, and to identify influential users or clusters of users who are particularly active."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848176bc",
   "metadata": {},
   "source": [
    "# POSSIBLE RQ'S :    \n",
    "\n",
    "    RQ 1 : How has social media influenced cultural perceptions and attitudes towards social issues, such as        gender, race, and sexuality, in different countries over the years?\n",
    "    \n",
    "    RQ 2: How have cultural values and traditions evolved over time in response to social media trends and         activities, and what are the implications of these changes for cultural identity and diversity?\n",
    "    \n",
    "    RQ 3: How can we measure the impact of social media use on cultural perceptions and attitudes towards social   issues, and how can we use these metrics to inform the design and development of effective social media   tools and interventions?\n",
    "    \n",
    "    RQ 4: What are the ethical implications of using social media data to study cultural trends and practices, and how can we ensure that such research is conducted in a responsible and respectful manner?\n",
    "    \n",
    "    RQ 5: How do individuals from different cultural backgrounds perceive the role of social media in shaping their understanding and attitudes towards social issues?\n",
    "\n",
    "    RQ 6: How can we use data analysis and machine learning techniques to identify patterns of social media use and perception related to social issues, and how can we translate these insights into actionable strategies             for promoting positive change?\n",
    "    \n",
    "    RQ 7: How do different machine learning models compare in their ability to accurately analyze and classify     social media data related to a specific topic, and how can we optimize these models to enhance their               performance in understanding public sentiment and predicting trends?\n",
    "    \n",
    "    RQ 8: What machine learning algorithms are most effective in identifying patterns of social media use and       perception related to social issues, and how can we optimize these algorithms to improve their accuracy             and effectiveness?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0ace405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c7445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtag_query = \"BlackLivesMatter OR #BlackLivesMatter OR BLM OR #BLM\"\n",
    "search_query = 'climatechange OR #climatechange OR globalwarming OR #globalwarming OR environment OR #environment OR climatestrike OR #climatestrike OR climatecrisis OR #climatecrisis OR climateaction OR #climateaction'\n",
    "limit = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22005333",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_as_string = str(limit)\n",
    "filename = \"/Users/alenjose/Desktop/msc_project/data\" \\\n",
    "                   + limit_as_string + \"_tweets_\" + search_query.split()[0] + \"_\" + \\\n",
    "                                       str(date.today().strftime(\"%m-%d-%y\")) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "519e3de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename Generated:  /Users/alenjose/Desktop/msc_project/data10_tweets_climatechange_04-23-23.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Filename Generated: \", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cc2271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "twitter_profile_url = \"https://twitter.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "262141ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "sleep_time = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "989fa6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COUNT : 2000 Sleeping for  15.0  minutes\n",
      "COUNT : 4000 Sleeping for  15.0  minutes\n",
      "COUNT : 6000 Sleeping for  15.0  minutes\n",
      "COUNT : 8000 Sleeping for  15.0  minutes\n",
      "COUNT : 10000 Sleeping for  15.0  minutes\n",
      "COUNT : 12000 Sleeping for  15.0  minutes\n",
      "COUNT : 14000 Sleeping for  15.0  minutes\n",
      "COUNT : 16000 Sleeping for  15.0  minutes\n",
      "COUNT : 18000 Sleeping for  15.0  minutes\n",
      "COUNT : 20000 Sleeping for  15.0  minutes\n",
      "COUNT : 22000 Sleeping for  15.0  minutes\n",
      "COUNT : 24000 Sleeping for  15.0  minutes\n",
      "COUNT : 26000 Sleeping for  15.0  minutes\n",
      "COUNT : 28000 Sleeping for  15.0  minutes\n",
      "COUNT : 30000 Sleeping for  15.0  minutes\n",
      "COUNT : 32000 Sleeping for  15.0  minutes\n",
      "COUNT : 34000 Sleeping for  15.0  minutes\n",
      "COUNT : 36000 Sleeping for  15.0  minutes\n",
      "COUNT : 38000 Sleeping for  15.0  minutes\n",
      "COUNT : 40000 Sleeping for  15.0  minutes\n",
      "COUNT : 42000 Sleeping for  15.0  minutes\n",
      "COUNT : 44000 Sleeping for  15.0  minutes\n",
      "COUNT : 46000 Sleeping for  15.0  minutes\n",
      "COUNT : 48000 Sleeping for  15.0  minutes\n",
      "COUNT : 50000 Sleeping for  15.0  minutes\n",
      "COUNT : 52000 Sleeping for  15.0  minutes\n",
      "COUNT : 54000 Sleeping for  15.0  minutes\n",
      "COUNT : 56000 Sleeping for  15.0  minutes\n",
      "COUNT : 58000 Sleeping for  15.0  minutes\n",
      "COUNT : 60000 Sleeping for  15.0  minutes\n",
      "COUNT : 62000 Sleeping for  15.0  minutes\n",
      "COUNT : 64000 Sleeping for  15.0  minutes\n",
      "COUNT : 66000 Sleeping for  15.0  minutes\n",
      "COUNT : 68000 Sleeping for  15.0  minutes\n",
      "COUNT : 70000 Sleeping for  15.0  minutes\n",
      "COUNT : 72000 Sleeping for  15.0  minutes\n",
      "COUNT : 74000 Sleeping for  15.0  minutes\n",
      "COUNT : 76000 Sleeping for  15.0  minutes\n",
      "COUNT : 78000 Sleeping for  15.0  minutes\n",
      "COUNT : 80000 Sleeping for  15.0  minutes\n",
      "COUNT : 82000 Sleeping for  15.0  minutes\n",
      "COUNT : 84000 Sleeping for  15.0  minutes\n",
      "COUNT : 86000 Sleeping for  15.0  minutes\n",
      "COUNT : 88000 Sleeping for  15.0  minutes\n",
      "COUNT : 90000 Sleeping for  15.0  minutes\n",
      "COUNT : 92000 Sleeping for  15.0  minutes\n",
      "COUNT : 94000 Sleeping for  15.0  minutes\n",
      "COUNT : 96000 Sleeping for  15.0  minutes\n",
      "COUNT : 98000 Sleeping for  15.0  minutes\n",
      "COUNT : 100000 Sleeping for  15.0  minutes\n"
     ]
    }
   ],
   "source": [
    "for tweet in sntwitter.TwitterSearchScraper(search_query).get_items():\n",
    "    if len(tweets) != limit:\n",
    "        count = count + 1\n",
    "        if count % 2000 == 0:\n",
    "            print(\"COUNT :\", count, \"Sleeping for \", sleep_time/60, \" minutes\")\n",
    "            time.sleep(sleep_time)\n",
    "        tweets.append([\n",
    "            tweet.date,\n",
    "            tweet.rawContent,\n",
    "            tweet.renderedContent,\n",
    "            tweet.id,\n",
    "            tweet.user.username,\n",
    "            tweet.user.displayname,\n",
    "            tweet.user.id,\n",
    "            tweet.user.renderedDescription,\n",
    "            tweet.user.verified,\n",
    "            tweet.user.created,\n",
    "            tweet.user.followersCount,\n",
    "            tweet.user.friendsCount,\n",
    "            tweet.user.statusesCount,\n",
    "            tweet.user.location,\n",
    "            tweet.replyCount,\n",
    "            tweet.retweetCount,\n",
    "            tweet.likeCount,\n",
    "            tweet.quoteCount,\n",
    "            tweet.lang,\n",
    "            tweet.source,\n",
    "            tweet.retweetedTweet,\n",
    "            tweet.quotedTweet,\n",
    "            tweet.mentionedUsers,\n",
    "            tweet.hashtags\n",
    "        ])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5abb3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>tweet_rendered_content</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>display_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_description</th>\n",
       "      <th>verified</th>\n",
       "      <th>user_profile_created</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_reply_count</th>\n",
       "      <th>tweet_retweet_count</th>\n",
       "      <th>tweet_like_count</th>\n",
       "      <th>tweet_quote_count</th>\n",
       "      <th>tweet_language</th>\n",
       "      <th>tweet_source</th>\n",
       "      <th>rt_original_tweet_id</th>\n",
       "      <th>quoted_tweet_original_tweet_id</th>\n",
       "      <th>tweet_mentioned_users</th>\n",
       "      <th>tweet_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-04 23:12:18+00:00</td>\n",
       "      <td>@paskyyx ROENG KOK GWA BLM BERAK2 JG SIüò≠</td>\n",
       "      <td>@paskyyx ROENG KOK GWA BLM BERAK2 JG SIüò≠</td>\n",
       "      <td>1643391069357490176</td>\n",
       "      <td>rizatimbel</td>\n",
       "      <td>rz-</td>\n",
       "      <td>1609439037332549637</td>\n",
       "      <td>suka anime, jpop, ngeluh rl</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-01-01 06:39:29+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>in</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/paskyyx]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-04 23:12:15+00:00</td>\n",
       "      <td>@ServusDeiVivi @proabortcomrade What does biol...</td>\n",
       "      <td>@ServusDeiVivi @proabortcomrade What does biol...</td>\n",
       "      <td>1643391058049466370</td>\n",
       "      <td>FredVIII1454</td>\n",
       "      <td>FredVIII-DFH-BLM ü¶è</td>\n",
       "      <td>793893711935631361</td>\n",
       "      <td>Not my real name.\\nHe/Him.\\nI cannot conceive ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-11-02 19:13:05+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/ServusDeiVivi, https://tw...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-04 23:12:12+00:00</td>\n",
       "      <td>@SundaeDivine @RonFilipkowski I'm surprised sh...</td>\n",
       "      <td>@SundaeDivine @RonFilipkowski I'm surprised sh...</td>\n",
       "      <td>1643391043822579712</td>\n",
       "      <td>ab_cann</td>\n",
       "      <td>Dick Fritter (The Inevitable Return)</td>\n",
       "      <td>1409539734062309376</td>\n",
       "      <td>üôàüôâüôä Proud PFLAG üè≥Ô∏è‚Äçüåàüè≥Ô∏è‚Äçüåàüè≥Ô∏è‚Äçüåà Staunch atheist. ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-06-28 15:55:30+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://twitter.com/SundaeDivine, https://twi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  \\\n",
       "0 2023-04-04 23:12:18+00:00   \n",
       "1 2023-04-04 23:12:15+00:00   \n",
       "2 2023-04-04 23:12:12+00:00   \n",
       "\n",
       "                                       tweet_content  \\\n",
       "0           @paskyyx ROENG KOK GWA BLM BERAK2 JG SIüò≠   \n",
       "1  @ServusDeiVivi @proabortcomrade What does biol...   \n",
       "2  @SundaeDivine @RonFilipkowski I'm surprised sh...   \n",
       "\n",
       "                              tweet_rendered_content             tweet_id  \\\n",
       "0           @paskyyx ROENG KOK GWA BLM BERAK2 JG SIüò≠  1643391069357490176   \n",
       "1  @ServusDeiVivi @proabortcomrade What does biol...  1643391058049466370   \n",
       "2  @SundaeDivine @RonFilipkowski I'm surprised sh...  1643391043822579712   \n",
       "\n",
       "      user_name                          display_name              user_id  \\\n",
       "0    rizatimbel                                   rz-  1609439037332549637   \n",
       "1  FredVIII1454                    FredVIII-DFH-BLM ü¶è   793893711935631361   \n",
       "2       ab_cann  Dick Fritter (The Inevitable Return)  1409539734062309376   \n",
       "\n",
       "                                    user_description  verified  \\\n",
       "0                        suka anime, jpop, ngeluh rl     False   \n",
       "1  Not my real name.\\nHe/Him.\\nI cannot conceive ...     False   \n",
       "2  üôàüôâüôä Proud PFLAG üè≥Ô∏è‚Äçüåàüè≥Ô∏è‚Äçüåàüè≥Ô∏è‚Äçüåà Staunch atheist. ...     False   \n",
       "\n",
       "       user_profile_created  ...  tweet_reply_count  tweet_retweet_count  \\\n",
       "0 2023-01-01 06:39:29+00:00  ...                  0                    0   \n",
       "1 2016-11-02 19:13:05+00:00  ...                  0                    0   \n",
       "2 2021-06-28 15:55:30+00:00  ...                  0                    0   \n",
       "\n",
       "   tweet_like_count tweet_quote_count  tweet_language  \\\n",
       "0                 0                 0              in   \n",
       "1                 0                 0              en   \n",
       "2                 0                 0              en   \n",
       "\n",
       "                                        tweet_source  rt_original_tweet_id  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...                  None   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                  None   \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                  None   \n",
       "\n",
       "   quoted_tweet_original_tweet_id  \\\n",
       "0                            None   \n",
       "1                            None   \n",
       "2                            None   \n",
       "\n",
       "                               tweet_mentioned_users tweet_hashtags  \n",
       "0                      [https://twitter.com/paskyyx]           None  \n",
       "1  [https://twitter.com/ServusDeiVivi, https://tw...           None  \n",
       "2  [https://twitter.com/SundaeDivine, https://twi...           None  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tweets, columns=[\n",
    "    'date',\n",
    "    'tweet_content',\n",
    "    'tweet_rendered_content',\n",
    "    'tweet_id',\n",
    "    'user_name',\n",
    "    'display_name',\n",
    "    'user_id',\n",
    "    'user_description',\n",
    "    'verified',\n",
    "    'user_profile_created',\n",
    "    'user_follower_count',\n",
    "    'user_friend_count',\n",
    "    'user_statuses_count',\n",
    "    'user_location',\n",
    "    'tweet_reply_count',\n",
    "    'tweet_retweet_count',\n",
    "    'tweet_like_count',\n",
    "    'tweet_quote_count',\n",
    "    'tweet_language',\n",
    "    'tweet_source',\n",
    "    'rt_original_tweet_id',\n",
    "    'quoted_tweet_original_tweet_id',\n",
    "    'tweet_mentioned_users',\n",
    "    'tweet_hashtags'\n",
    "])\n",
    "\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3db86680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3503d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0379d578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&include_ext_has_nft_avatar=1&include_ext_is_blue_verified=1&include_ext_verified_type=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_ext_limited_action_results=false&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_ext_collab_control=true&include_ext_views=true&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&include_ext_sensitive_media_warning=true&include_ext_trusted_friends_metadata=true&send_error_codes=true&simple_quoted_tweet=true&q=black+lives+matter+since%3A2020-01-01+until%3A2020-01-31&tweet_search_mode=live&count=20&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&include_ext_edit_control=true&ext=mediaStats%2ChighlightedLabel%2ChasNftAvatar%2CvoiceInfo%2Cenrichments%2CsuperFollowMetadata%2CunmentionInfo%2CeditControl%2Ccollab_control%2Cvibe: blocked (403)\n",
      "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&include_ext_has_nft_avatar=1&include_ext_is_blue_verified=1&include_ext_verified_type=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_ext_limited_action_results=false&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_ext_collab_control=true&include_ext_views=true&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&include_ext_sensitive_media_warning=true&include_ext_trusted_friends_metadata=true&send_error_codes=true&simple_quoted_tweet=true&q=black+lives+matter+since%3A2020-01-01+until%3A2020-01-31&tweet_search_mode=live&count=20&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&include_ext_edit_control=true&ext=mediaStats%2ChighlightedLabel%2ChasNftAvatar%2CvoiceInfo%2Cenrichments%2CsuperFollowMetadata%2CunmentionInfo%2CeditControl%2Ccollab_control%2Cvibe failed, giving up.\n",
      "Errors: blocked (403), blocked (403), blocked (403), blocked (403)\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&include_ext_has_nft_avatar=1&include_ext_is_blue_verified=1&include_ext_verified_type=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_ext_limited_action_results=false&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_ext_collab_control=true&include_ext_views=true&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&include_ext_sensitive_media_warning=true&include_ext_trusted_friends_metadata=true&send_error_codes=true&simple_quoted_tweet=true&q=black+lives+matter+since%3A2020-01-01+until%3A2020-01-31&tweet_search_mode=live&count=20&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&include_ext_edit_control=true&ext=mediaStats%2ChighlightedLabel%2ChasNftAvatar%2CvoiceInfo%2Cenrichments%2CsuperFollowMetadata%2CunmentionInfo%2CeditControl%2Ccollab_control%2Cvibe failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/29/2_xxbt5d1gn7b5yqm290y2hh0000gn/T/ipykernel_59005/2658223480.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdate_ranges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{keyword} since:{start_date.strftime(\"%Y-%m-%d\")} until:{end_date.strftime(\"%Y-%m-%d\")}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterSearchScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnum_tweets_per_month\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36mget_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cursor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://api.twitter.com/2/search/adaptive.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaginationParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1662\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_timeline_instructions_to_tweets_or_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_iter_api_data\u001b[0;34m(self, endpoint, apiType, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Retrieving scroll page {cursor}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_api_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapiType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreqParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/snscrape/modules/twitter.py\u001b[0m in \u001b[0;36m_get_api_data\u001b[0;34m(self, endpoint, apiType, params)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mapiType\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_TwitterAPIType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRAPHQL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote_via\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apiHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponseOkCallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_api_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_post\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/snscrape/base.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    245\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                         \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfatal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Errors: {\", \".join(errors)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mScraperException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reached unreachable code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mScraperException\u001b[0m: 4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&include_ext_has_nft_avatar=1&include_ext_is_blue_verified=1&include_ext_verified_type=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_ext_limited_action_results=false&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_ext_collab_control=true&include_ext_views=true&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&include_ext_sensitive_media_warning=true&include_ext_trusted_friends_metadata=true&send_error_codes=true&simple_quoted_tweet=true&q=black+lives+matter+since%3A2020-01-01+until%3A2020-01-31&tweet_search_mode=live&count=20&query_source=spelling_expansion_revert_click&pc=1&spelling_corrections=1&include_ext_edit_control=true&ext=mediaStats%2ChighlightedLabel%2ChasNftAvatar%2CvoiceInfo%2Cenrichments%2CsuperFollowMetadata%2CunmentionInfo%2CeditControl%2Ccollab_control%2Cvibe failed, giving up."
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "keyword = 'black lives matter'\n",
    "num_tweets_per_month = 1\n",
    "start_year = 2020\n",
    "end_year = 2023\n",
    "\n",
    "# Prepare date ranges for each month\n",
    "date_ranges = []\n",
    "for year in range(start_year, end_year + 1):\n",
    "    for month in range(1, 13):\n",
    "        start_date = datetime(year, month, 1)\n",
    "        end_date = start_date + pd.DateOffset(months=1) - timedelta(days=1)\n",
    "        date_ranges.append((start_date, end_date))\n",
    "\n",
    "# Scrape tweets\n",
    "tweets = []\n",
    "for start_date, end_date in date_ranges:\n",
    "    query = f'{keyword} since:{start_date.strftime(\"%Y-%m-%d\")} until:{end_date.strftime(\"%Y-%m-%d\")}'\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "        if i >= num_tweets_per_month:\n",
    "            break\n",
    "        tweets.append(tweet)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(t.__dict__ for t in tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa97bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
